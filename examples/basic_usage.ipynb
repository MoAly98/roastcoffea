{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# roastcoffea: Comprehensive Performance Monitoring for Coffea\n\nThis notebook demonstrates all features of roastcoffea including:\n- Basic metrics collection\n- Chunk-level tracking with `@track_metrics`\n- Byte tracking for I/O analysis\n- Fine-grained profiling with `track_time()` and `track_memory()`\n- Complete visualization suite (17 plot types)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from contextlib import contextmanager\nfrom pathlib import Path\n\nimport awkward as ak\nimport matplotlib.pyplot as plt\nfrom coffea import processor\nfrom coffea.nanoevents import NanoAODSchema\nfrom dask.distributed import Client, LocalCluster\n\nfrom roastcoffea import (\n    MetricsCollector,\n    track_bytes,\n    track_memory,\n    track_metrics,\n    track_time,\n)\nfrom roastcoffea.visualization.plots import (\n    plot_compression_ratio_distribution,\n    plot_cpu_utilization_timeline,\n    plot_data_access_percentage,\n    plot_efficiency_summary,\n    plot_executing_tasks_timeline,\n    plot_memory_utilization_timeline,\n    plot_occupancy_timeline,\n    plot_per_task_bytes_read,\n    plot_per_task_cpu_io,\n    plot_per_task_overhead,\n    plot_resource_utilization,\n    plot_runtime_distribution,\n    plot_runtime_vs_events,\n    plot_throughput_timeline,\n    plot_total_active_tasks_timeline,\n    plot_worker_activity_timeline,\n    plot_worker_count_timeline,\n)\n\n# Configure matplotlib for inline display\n%matplotlib inline\nplt.style.use('seaborn-v0_8-darkgrid')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def acquire_client(n_workers=4, threads_per_worker=1):\n",
    "    \"\"\"Context manager for Dask client.\"\"\"\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=n_workers,\n",
    "        threads_per_worker=threads_per_worker,\n",
    "        processes=True,\n",
    "    )\n",
    "    client = Client(cluster)\n",
    "    print(f\"Dashboard: {client.dashboard_link}\")\n",
    "\n",
    "    try:\n",
    "        yield client\n",
    "    finally:\n",
    "        client.close()\n",
    "        cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Setup\n",
    "\n",
    "Using CERN Open Data for reproducible demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileset = {\n",
    "    \"ttbar\": {\n",
    "        \"files\": {\n",
    "            \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/120000/08FCB2ED-176B-064B-85AB-37B898773B98.root\": \"Events\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Featured Processor\n",
    "\n",
    "This processor demonstrates all roastcoffea tracking features:\n",
    "- `@track_metrics`: Automatic chunk-level metrics (timing, memory, bytes)\n",
    "- `track_bytes()`: Fine-grained I/O tracking for specific data access\n",
    "- `track_time()`: Time profiling for code sections\n",
    "- `track_memory()`: Memory profiling for code sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComprehensiveProcessor(processor.ProcessorABC):\n",
    "    \"\"\"Processor with all roastcoffea features enabled.\"\"\"\n",
    "\n",
    "    @track_metrics\n",
    "    def process(self, events):\n",
    "        # Track jet loading I/O\n",
    "        with track_bytes(self, events, \"jet_loading\"):\n",
    "            with track_time(self, \"jet_selection\"):\n",
    "                jets = events.Jet\n",
    "                selected_jets = jets[jets.pt > 30]\n",
    "\n",
    "        # Track muon loading I/O\n",
    "        with track_bytes(self, events, \"muon_loading\"):\n",
    "            with track_time(self, \"muon_selection\"):\n",
    "                muons = events.Muon\n",
    "                selected_muons = muons[muons.pt > 20]\n",
    "\n",
    "        # Track memory-intensive computations\n",
    "        with track_memory(self, \"pt_calculations\"):\n",
    "            jet_pt_sum = ak.sum(selected_jets.pt, axis=1)\n",
    "            muon_pt_sum = ak.sum(selected_muons.pt, axis=1)\n",
    "\n",
    "        return {\n",
    "            \"nevents\": len(events),\n",
    "            \"njets\": len(selected_jets),\n",
    "            \"nmuons\": len(selected_muons),\n",
    "        }\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis with Metrics Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehensive_processor = ComprehensiveProcessor()\n",
    "\n",
    "with acquire_client(n_workers=4) as client:\n",
    "    with MetricsCollector(\n",
    "        client=client,\n",
    "        processor_instance=comprehensive_processor,\n",
    "        track_workers=True,\n",
    "        worker_tracking_interval=1.0,\n",
    "    ) as collector:\n",
    "        executor = processor.DaskExecutor(client=client)\n",
    "        runner = processor.Runner(\n",
    "            executor=executor,\n",
    "            schema=NanoAODSchema,\n",
    "            chunksize=100_000,\n",
    "            savemetrics=True,\n",
    "        )\n",
    "\n",
    "        output, report = runner(\n",
    "            fileset,\n",
    "            processor_instance=comprehensive_processor,\n",
    "            treename=\"Events\",\n",
    "        )\n",
    "\n",
    "        # Extract chunk metrics from output\n",
    "        collector.extract_metrics_from_output(output)\n",
    "        collector.set_coffea_report(report)\n",
    "\n",
    "    # Print summary tables\n",
    "    collector.print_summary()\n",
    "\n",
    "# Get metrics for plotting\n",
    "metrics = collector.get_metrics()\n",
    "tracking_data = collector.tracking_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Performance Visualizations\n\nroastcoffea provides 17 different plot types organized into categories:\n\n### 1. Throughput & Data I/O\n### 2. Worker Resource Utilization\n### 3. Chunk-level Analysis\n### 4. Per-Task Analysis\n### 5. Summary Metrics"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Throughput & Data I/O\n\nTrack data processing rates, I/O patterns, file compression, and data access efficiency."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Throughput Timeline (requires byte tracking)\n",
    "if \"chunk_info\" in metrics and metrics[\"chunk_info\"]:\n",
    "    print(\"üìä Data Throughput Over Time\")\n",
    "    fig, ax = plot_throughput_timeline(\n",
    "        chunk_info=metrics[\"chunk_info\"],\n",
    "        tracking_data=tracking_data,\n",
    "        title=\"Data Throughput Timeline\",\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Byte tracking not available. Throughput plot requires @track_metrics decorator.\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Compression Ratio Distribution\nif \"compression_ratios\" in metrics and metrics[\"compression_ratios\"]:\n    print(\"üìä Compression Ratio Distribution Across Files\")\n    print(\"   Shows compression efficiency (compressed/uncompressed)\")\n    try:\n        fig, ax = plot_compression_ratio_distribution(metrics)\n        plt.show()\n    except Exception as e:\n        print(f\"   Plot unavailable: {e}\")\nelse:\n    print(\"‚ö†Ô∏è  Compression ratio data not available\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Bytes Read Percentage Distribution\nif \"bytes_read_percent_per_file\" in metrics and metrics[\"bytes_read_percent_per_file\"]:\n    print(\"üìä Bytes Read Percentage Distribution\")\n    print(\"   Shows what % of each file's bytes were actually read\")\n    try:\n        fig, ax = plot_data_access_percentage(metrics)\n        plt.show()\n    except Exception as e:\n        print(f\"   Plot unavailable: {e}\")\nelse:\n    print(\"‚ö†Ô∏è  Bytes read percentage data not available\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker Resource Utilization\n",
    "\n",
    "Monitor worker activity, task distribution, and resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worker Count Over Time\n",
    "if tracking_data and \"worker_counts\" in tracking_data:\n",
    "    print(\"üìä Worker Count Over Time\")\n",
    "    fig, ax = plot_worker_count_timeline(tracking_data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worker Activity Timeline (active tasks per worker)\n",
    "if tracking_data and \"worker_active_tasks\" in tracking_data:\n",
    "    print(\"üìä Worker Activity Timeline\")\n",
    "    print(\"   Shows active (processing + queued) tasks per worker\")\n",
    "    fig, ax = plot_worker_activity_timeline(\n",
    "        tracking_data,\n",
    "        max_legend_entries=5  # Hide legend if >5 workers\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Active Tasks Across All Workers\n",
    "if tracking_data and \"worker_active_tasks\" in tracking_data:\n",
    "    print(\"üìä Total Active Tasks Across All Workers\")\n",
    "    fig, ax = plot_total_active_tasks_timeline(tracking_data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worker Occupancy (task saturation)\n",
    "if tracking_data and \"worker_occupancy\" in tracking_data:\n",
    "    print(\"üìä Worker Occupancy (Task Saturation)\")\n",
    "    print(\"   0.0 = idle, higher values = more saturated\")\n",
    "    fig, ax = plot_occupancy_timeline(\n",
    "        tracking_data,\n",
    "        max_legend_entries=5\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing Tasks Per Worker\n",
    "if tracking_data and \"worker_executing\" in tracking_data:\n",
    "    print(\"üìä Executing Tasks Per Worker\")\n",
    "    print(\"   Shows tasks actually running (subset of active tasks)\")\n",
    "    fig, ax = plot_executing_tasks_timeline(\n",
    "        tracking_data,\n",
    "        max_legend_entries=5\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory Utilization\n",
    "if tracking_data and \"worker_memory\" in tracking_data:\n",
    "    print(\"üìä Memory Utilization Per Worker\")\n",
    "    fig, ax = plot_memory_utilization_timeline(tracking_data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "source": "# CPU Utilization Per Worker\nif tracking_data and \"worker_cpu\" in tracking_data:\n    print(\"üìä CPU Utilization Per Worker\")\n    print(\"   Shows CPU usage percentage (0-100%) for each worker\")\n    fig, ax = plot_cpu_utilization_timeline(\n        tracking_data,\n        max_legend_entries=5\n    )\n    plt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Chunk-level Analysis\n\nPerformance metrics for individual chunks (runtime, events processed).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Chunk Runtime Distribution\nif \"raw_chunk_metrics\" in metrics and metrics[\"raw_chunk_metrics\"]:\n    print(\"üìä Chunk Runtime Distribution\")\n    print(\"   Histogram of processing time per chunk\")\n    try:\n        fig, ax = plot_runtime_distribution(\n            chunk_metrics=metrics[\"raw_chunk_metrics\"]\n        )\n        plt.show()\n    except Exception as e:\n        print(f\"   Plot unavailable: {e}\")\nelse:\n    print(\"‚ö†Ô∏è  Chunk metrics not available\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Chunk Runtime vs Number of Events\nif \"raw_chunk_metrics\" in metrics and metrics[\"raw_chunk_metrics\"]:\n    print(\"üìä Chunk Runtime vs Number of Events\")\n    print(\"   Scatter plot showing scaling behavior\")\n    try:\n        fig, ax = plot_runtime_vs_events(\n            chunk_metrics=metrics[\"raw_chunk_metrics\"]\n        )\n        plt.show()\n    except Exception as e:\n        print(f\"   Plot unavailable: {e}\")\nelse:\n    print(\"‚ö†Ô∏è  Chunk metrics not available\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Task Analysis\n",
    "\n",
    "Fine-grained metrics from Dask Spans for individual task performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_metrics = getattr(collector, 'span_metrics', None)\n",
    "\n",
    "if span_metrics:\n",
    "    # CPU vs I/O Breakdown\n",
    "    print(\"üìä Per-Task CPU vs I/O Time\")\n",
    "    try:\n",
    "        fig, ax = plot_per_task_cpu_io(span_metrics)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"   Plot unavailable: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Span metrics not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if span_metrics:\n",
    "    # Bytes Read Per Task\n",
    "    print(\"üìä Per-Task Bytes Read\")\n",
    "    try:\n",
    "        fig, ax = plot_per_task_bytes_read(span_metrics)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"   Plot unavailable: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if span_metrics:\n",
    "    # Compression & Serialization Overhead\n",
    "    print(\"üìä Per-Task Compression & Serialization Overhead\")\n",
    "    try:\n",
    "        fig, ax = plot_per_task_overhead(span_metrics)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"   Plot unavailable: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Metrics\n",
    "\n",
    "High-level overview of overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficiency Summary\n",
    "print(\"üìä Efficiency Summary\")\n",
    "fig, ax = plot_efficiency_summary(metrics)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource Utilization Summary\n",
    "print(\"üìä Resource Utilization\")\n",
    "fig, ax = plot_resource_utilization(metrics)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Raw Metrics\n",
    "\n",
    "All metrics are accessible programmatically for custom analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall metrics\n",
    "print(\"=\" * 60)\n",
    "print(\"KEY METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total events: {metrics.get('total_events', 0):,}\")\n",
    "print(f\"Total bytes read: {metrics.get('total_bytes_read_coffea', 0) / 1e9:.2f} GB\")\n",
    "print(f\"Overall throughput: {metrics.get('overall_rate_gbps', 0):.2f} Gbps\")\n",
    "print(f\"Wall time: {metrics.get('wall_time', 0):.2f}s\")\n",
    "print(f\"Core efficiency: {metrics.get('core_efficiency', 0):.1f}%\")\n",
    "print(f\"Number of chunks: {metrics.get('num_chunks', 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-chunk metrics (if available)\n",
    "if \"raw_chunk_metrics\" in metrics:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CHUNK-LEVEL DETAILS (first 3 chunks)\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, chunk in enumerate(metrics[\"raw_chunk_metrics\"][:3]):\n",
    "        print(f\"\\nChunk {i+1}:\")\n",
    "        print(f\"  Events: {chunk.get('num_events', 0):,}\")\n",
    "        print(f\"  Duration: {chunk.get('duration', 0):.2f}s\")\n",
    "        print(f\"  Bytes read: {chunk.get('bytes_read', 0) / 1e6:.2f} MB\")\n",
    "        print(f\"  Memory delta: {chunk.get('mem_delta_mb', 0):+.1f} MB\")\n",
    "        \n",
    "        # Fine-grained timing\n",
    "        if \"timing\" in chunk and chunk[\"timing\"]:\n",
    "            print(\"  Timing breakdown:\")\n",
    "            for section, duration in chunk[\"timing\"].items():\n",
    "                print(f\"    {section}: {duration:.3f}s\")\n",
    "        \n",
    "        # Fine-grained bytes\n",
    "        if \"bytes\" in chunk and chunk[\"bytes\"]:\n",
    "            print(\"  I/O breakdown:\")\n",
    "            for section, bytes_count in chunk[\"bytes\"].items():\n",
    "                print(f\"    {section}: {bytes_count / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading Measurements\n",
    "\n",
    "Persist metrics for later analysis or comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save measurement\n",
    "output_dir = Path(\"measurements\")\n",
    "measurement_path = collector.save_measurement(\n",
    "    output_dir, measurement_name=\"comprehensive_demo\"\n",
    ")\n",
    "print(f\"‚úÖ Saved to: {measurement_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load it back\n",
    "from roastcoffea.export.measurements import load_measurement\n",
    "\n",
    "loaded = load_measurement(measurement_path)\n",
    "print(f\"‚úÖ Loaded metrics from {measurement_path}\")\n",
    "print(f\"   Events processed: {loaded['metrics']['total_events']:,}\")\n",
    "print(f\"   Throughput: {loaded['metrics']['overall_rate_gbps']:.2f} Gbps\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}